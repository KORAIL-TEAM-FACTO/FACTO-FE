import { io, Socket } from 'socket.io-client'

const API_BASE_URL = import.meta.env.VITE_API_BASE_URL || 'http://localhost:3000/api/v1'
const WEBSOCKET_URL = import.meta.env.VITE_WEBSOCKET_URL || 'http://localhost:3000/signaling'

// VAD ì„¤ì •
const VOLUME_THRESHOLD = -19 // dB (19 ë°ì‹œë²¨ ì´ìƒë§Œ ê°ì§€)
const SILENCE_DURATION = 1000 // 1ì´ˆ
const CHECK_INTERVAL = 100 // 100ms
const MINIMUM_RECORDING_DURATION = 3000 // 3ì´ˆ - ìµœì†Œ ë…¹ìŒ ì‹œê°„

export interface CallData {
  id: string
  sessionId: string
  callerNumber: string
  status: string
  createdAt: string
}

export interface WebRTCConfig {
  iceServers: RTCIceServer[]
  iceCandidatePoolSize: number
  iceTransportPolicy: RTCIceTransportPolicy
  bundlePolicy: RTCBundlePolicy
  rtcpMuxPolicy: RTCRtcpMuxPolicy
}

export interface VADStatus {
  volume: number
  isSpeaking: boolean
  isAIResponding: boolean
  audioSentCount: number
  aiResponseCount: number
}

class WebRTCService {
  private peerConnection: RTCPeerConnection | null = null
  private localStream: MediaStream | null = null
  private socket: Socket | null = null
  private callId: string | null = null
  private sessionId: string | null = null
  private peerId: string = `client-${Date.now()}`

  // VAD ê´€ë ¨
  private audioContext: AudioContext | null = null
  private analyser: AnalyserNode | null = null
  private mediaRecorder: MediaRecorder | null = null
  private recordedChunks: Blob[] = []
  private isRecording = false
  private isAIResponding = false
  private isWaitingForAIResponse = false // ìš”ì²­ ì „ì†¡ í›„ ì‘ë‹µ ëŒ€ê¸° ì¤‘
  private lastSpeechTime = 0
  private isSpeaking = false
  private vadCheckInterval: ReturnType<typeof setInterval> | null = null
  private audioSentCount = 0
  private aiResponseCount = 0
  private lastAudioSentTime = 0 // ë§ˆì§€ë§‰ ì˜¤ë””ì˜¤ ì „ì†¡ ì‹œê°„
  private recordingStartTime = 0 // ë…¹ìŒ ì‹œì‘ ì‹œê°„

  // ì½œë°±
  private onVADStatusChange?: (status: VADStatus) => void
  private onAIResponse?: (audioBlob: Blob) => void
  private onFirstAIResponse?: () => void

  async getWebRTCConfig(): Promise<WebRTCConfig> {
    const response = await fetch(`${API_BASE_URL}/calls/config`)
    const data = await response.json()
    return data.data.config
  }

  async startCall(callerNumber: string): Promise<CallData> {
    const response = await fetch(`${API_BASE_URL}/calls`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ callerNumber }),
    })

    const data = await response.json()
    this.callId = data.data.call.id
    this.sessionId = data.data.call.sessionId
    return data.data.call
  }

  setVADStatusCallback(callback: (status: VADStatus) => void): void {
    this.onVADStatusChange = callback
  }

  setAIResponseCallback(callback: (audioBlob: Blob) => void): void {
    this.onAIResponse = callback
  }

  setFirstAIResponseCallback(callback: () => void): void {
    this.onFirstAIResponse = callback
  }

  private getVolume(): number {
    if (!this.analyser) return -100

    const dataArray = new Uint8Array(this.analyser.frequencyBinCount)
    this.analyser.getByteFrequencyData(dataArray)

    let sum = 0
    for (let i = 0; i < dataArray.length; i++) {
      sum += dataArray[i] * dataArray[i]
    }
    const rms = Math.sqrt(sum / dataArray.length)
    const db = 20 * Math.log10(rms / 255)

    return isFinite(db) ? db : -100
  }

  private emitVADStatus(): void {
    if (this.onVADStatusChange) {
      this.onVADStatusChange({
        volume: this.getVolume(),
        isSpeaking: this.isSpeaking,
        isAIResponding: this.isAIResponding,
        audioSentCount: this.audioSentCount,
        aiResponseCount: this.aiResponseCount,
      })
    }
  }

  private startVADChecking(): void {
    console.log(`ğŸ¤ VAD ì²´í¬ ì‹œì‘ (ì„ê³„ê°’: ${VOLUME_THRESHOLD}dB, ì¹¨ë¬µ: ${SILENCE_DURATION}ms)`)

    this.vadCheckInterval = setInterval(() => {
      if (!this.localStream) {
        this.emitVADStatus()
        return
      }

      // AI ì‘ë‹µ ëŒ€ê¸° ì¤‘ì´ê±°ë‚˜ AI ì‘ë‹µ ì¤‘ì´ë©´ ë…¹ìŒí•˜ì§€ ì•ŠìŒ
      if (this.isAIResponding || this.isWaitingForAIResponse) {
        // AI ì‘ë‹µ ëŒ€ê¸°/ì¤‘ì´ë©´ ë…¹ìŒ ì¤‘ì§€
        if (this.isRecording) {
          const elapsedSinceSent = this.lastAudioSentTime > 0
            ? ((Date.now() - this.lastAudioSentTime) / 1000).toFixed(2)
            : 'N/A'
          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          console.log(`âš ï¸ ${this.isWaitingForAIResponse ? 'AI ì‘ë‹µ ëŒ€ê¸° ì¤‘' : 'AI ì‘ë‹µ ì¤‘'} - ë…¹ìŒ ê°•ì œ ì¤‘ì§€`)
          console.log(`   ë§ˆì§€ë§‰ ì „ì†¡ í›„ ê²½ê³¼: ${elapsedSinceSent}ì´ˆ`)
          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          this.stopRecording()
          this.isSpeaking = false
        }
        this.emitVADStatus()
        return
      }

      const volume = this.getVolume()
      const now = Date.now()
      const silenceDuration = this.lastSpeechTime > 0 ? now - this.lastSpeechTime : 0

      // ë””ë²„ê¹…ìš© - 1ì´ˆë§ˆë‹¤ í˜„ì¬ ìƒíƒœ ì¶œë ¥
      if (now % 1000 < CHECK_INTERVAL) {
        console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
        console.log(`ğŸ“Š [VAD ì²´í¬] ${new Date().toLocaleTimeString()}.${now % 1000}`)
        console.log(`   ğŸ”Š ìŒëŸ‰: ${volume.toFixed(1)}dB (ì„ê³„ê°’: ${VOLUME_THRESHOLD}dB)`)
        console.log(`   ğŸ¤ isSpeaking: ${this.isSpeaking}`)
        console.log(`   âºï¸  isRecording: ${this.isRecording}`)
        console.log(`   â±ï¸  ì¹¨ë¬µ ì§€ì†: ${this.isSpeaking ? (silenceDuration / 1000).toFixed(2) + 'ì´ˆ' : 'N/A'}`)
        console.log(`   ğŸ“Š ìƒíƒœ: Waiting=${this.isWaitingForAIResponse}, Responding=${this.isAIResponding}`)
        console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
      }

      // ìŒì„± ê°ì§€ (-19dB ì´ìƒ)
      if (volume > VOLUME_THRESHOLD) {
        if (!this.isSpeaking) {
          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          console.log(`ğŸ™ï¸ [ìŒì„± ê°ì§€ ì‹œì‘] ${new Date().toLocaleTimeString()}.${now % 1000}`)
          console.log(`   ğŸ”Š ìŒëŸ‰: ${volume.toFixed(1)}dB > ${VOLUME_THRESHOLD}dB`)
          console.log(`   ğŸ“Š ìƒíƒœ ë³€ê²½ ì „:`)
          console.log(`      - isSpeaking: ${this.isSpeaking} â†’ true`)
          console.log(`      - isRecording: ${this.isRecording}`)
          console.log(`      - isWaitingForAIResponse: ${this.isWaitingForAIResponse}`)
          console.log(`      - isAIResponding: ${this.isAIResponding}`)

          this.isSpeaking = true
          console.log(`   âœ… isSpeaking = true ì„¤ì • ì™„ë£Œ`)

          if (!this.isRecording) {
            console.log(`   ğŸ¬ ë…¹ìŒ ì‹œì‘ í˜¸ì¶œ (startRecording)`)
            this.startRecording()
          } else {
            console.log(`   âš ï¸  ì´ë¯¸ ë…¹ìŒ ì¤‘ - startRecording í˜¸ì¶œ ì•ˆ í•¨`)
          }
          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
        }
        this.lastSpeechTime = now
      } else {
        // ì¹¨ë¬µ ì²´í¬ (-19dB ì´í•˜ê°€ 1ì´ˆ ë™ì•ˆ ì§€ì†)
        if (this.isSpeaking && silenceDuration > SILENCE_DURATION) {
          // ë…¹ìŒ ì‹œê°„ ì²´í¬ - 3ì´ˆ ë¯¸ë§Œì´ë©´ ì¹¨ë¬µ ê°ì§€ ë¬´ì‹œí•˜ê³  ê³„ì† ë…¹ìŒ
          const currentRecordingDuration = this.recordingStartTime > 0 ? now - this.recordingStartTime : 0

          if (currentRecordingDuration < MINIMUM_RECORDING_DURATION) {
            console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
            console.log(`â³ [ì¹¨ë¬µ ê°ì§€ ë¬´ì‹œ] ${new Date().toLocaleTimeString()}.${now % 1000}`)
            console.log(`   ğŸ”Š ìŒëŸ‰: ${volume.toFixed(1)}dB <= ${VOLUME_THRESHOLD}dB`)
            console.log(`   â±ï¸  ì¹¨ë¬µ ì§€ì†: ${(silenceDuration / 1000).toFixed(2)}ì´ˆ`)
            console.log(`   â±ï¸  ë…¹ìŒ ì‹œê°„: ${(currentRecordingDuration / 1000).toFixed(2)}ì´ˆ < ${MINIMUM_RECORDING_DURATION / 1000}ì´ˆ`)
            console.log(`   âš ï¸  ìµœì†Œ ë…¹ìŒ ì‹œê°„ ë¯¸ë‹¬ - ì¹¨ë¬µ ë¬´ì‹œí•˜ê³  ê³„ì† ë…¹ìŒ`)
            console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
            // ì¹¨ë¬µ ë¬´ì‹œí•˜ê³  ê³„ì† ë…¹ìŒ (isSpeaking ìœ ì§€)
          } else {
            console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
            console.log(`ğŸ”‡ [ì¹¨ë¬µ ê°ì§€] ${new Date().toLocaleTimeString()}.${now % 1000}`)
            console.log(`   ğŸ”Š ìŒëŸ‰: ${volume.toFixed(1)}dB <= ${VOLUME_THRESHOLD}dB`)
            console.log(`   â±ï¸  ì¹¨ë¬µ ì§€ì† ì‹œê°„: ${(silenceDuration / 1000).toFixed(2)}ì´ˆ > ${SILENCE_DURATION / 1000}ì´ˆ`)
            console.log(`   â±ï¸  ë…¹ìŒ ì‹œê°„: ${(currentRecordingDuration / 1000).toFixed(2)}ì´ˆ >= ${MINIMUM_RECORDING_DURATION / 1000}ì´ˆ`)
            console.log(`   ğŸ“Š ìƒíƒœ ë³€ê²½ ì „:`)
            console.log(`      - isSpeaking: ${this.isSpeaking} â†’ false`)
            console.log(`      - isRecording: ${this.isRecording}`)
            console.log(`      - isWaitingForAIResponse: ${this.isWaitingForAIResponse}`)
            console.log(`      - isAIResponding: ${this.isAIResponding}`)

            this.isSpeaking = false
            console.log(`   âœ… isSpeaking = false ì„¤ì • ì™„ë£Œ`)

            if (this.isRecording) {
              console.log(`   ğŸ›‘ ë…¹ìŒ ì¤‘ì§€ í˜¸ì¶œ (stopRecording)`)
              this.stopRecording()
            } else {
              console.log(`   âš ï¸  ë…¹ìŒ ì¤‘ì´ ì•„ë‹˜ - stopRecording í˜¸ì¶œ ì•ˆ í•¨`)
            }
            console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          }
        }
      }

      this.emitVADStatus()
    }, CHECK_INTERVAL)
  }

  private startRecording(): void {
    const now = Date.now()
    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
    console.log(`âºï¸ [startRecording í˜¸ì¶œ] ${new Date().toLocaleTimeString()}.${now % 1000}`)
    console.log(`   ğŸ“Š ìƒíƒœ:`)
    console.log(`      - isRecording: ${this.isRecording}`)
    console.log(`      - localStream: ${this.localStream ? 'âœ… ìˆìŒ' : 'âŒ ì—†ìŒ'}`)
    console.log(`      - isWaitingForAIResponse: ${this.isWaitingForAIResponse}`)
    console.log(`      - isAIResponding: ${this.isAIResponding}`)

    if (this.isRecording || !this.localStream) {
      const reason = this.isRecording ? 'ì´ë¯¸ ë…¹ìŒ ì¤‘' : 'localStream ì—†ìŒ'
      console.log(`   âš ï¸  ë…¹ìŒ ì‹œì‘ ë¶ˆê°€: ${reason}`)
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
      return
    }

    console.log(`   âœ… ë…¹ìŒ ì‹œì‘ ì¡°ê±´ ë§Œì¡±`)
    this.recordedChunks = []

    try {
      this.mediaRecorder = new MediaRecorder(this.localStream, {
        mimeType: 'audio/webm;codecs=opus',
      })
      console.log(`   âœ… MediaRecorder ìƒì„± ì™„ë£Œ`)

      this.mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          this.recordedChunks.push(e.data)
          console.log(`ğŸ“¦ ì²­í¬: ${(e.data.size / 1024).toFixed(1)}KB`)
        }
      }

      this.mediaRecorder.onstop = () => {
        const blob = new Blob(this.recordedChunks, { type: 'audio/webm' })
        const stopTime = Date.now()
        const recordingDuration = this.recordingStartTime > 0 ? stopTime - this.recordingStartTime : 0

        console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
        console.log(`â¹ï¸ [onstop ì½œë°±] ë…¹ìŒ ì™„ë£Œ`)
        console.log(`   ğŸ• ì™„ë£Œ ì‹œê°„: ${new Date().toLocaleTimeString()}.${stopTime % 1000}`)
        console.log(`   â±ï¸  ë…¹ìŒ ì‹œê°„: ${(recordingDuration / 1000).toFixed(2)}ì´ˆ`)
        console.log(`   ğŸ“¦ í¬ê¸°: ${(blob.size / 1024).toFixed(1)}KB`)
        console.log(`   ğŸ“Š í˜„ì¬ ìƒíƒœ:`)
        console.log(`      - isRecording: ${this.isRecording}`)
        console.log(`      - isWaitingForAIResponse: ${this.isWaitingForAIResponse ? 'â›” true' : 'âœ… false'}`)
        console.log(`      - isAIResponding: ${this.isAIResponding ? 'â›” true' : 'âœ… false'}`)

        // AI ìƒíƒœ ì²´í¬ - AI ëŒ€ê¸°/ì‘ë‹µ ì¤‘ì´ë©´ ì „ì†¡í•˜ì§€ ì•ŠìŒ
        if (this.isWaitingForAIResponse || this.isAIResponding) {
          const reason = this.isWaitingForAIResponse ? 'AI ì‘ë‹µ ëŒ€ê¸° ì¤‘' : 'AI ì‘ë‹µ ì¤‘'
          console.log(`âŒ [onstop ì°¨ë‹¨] ${reason} - sendAudio í˜¸ì¶œ ì•ˆ í•¨`)
          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          return
        }

        console.log(`âœ… [onstop í†µê³¼] ì¡°ê±´ ë§Œì¡± - sendAudio í˜¸ì¶œ`)
        console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
        this.sendAudio(blob)
      }

      this.mediaRecorder.start()
      this.isRecording = true
      this.recordingStartTime = Date.now()
      console.log(`   âœ… MediaRecorder.start() í˜¸ì¶œ ì™„ë£Œ`)
      console.log(`   ğŸ”’ isRecording = true ì„¤ì •`)
      console.log(`   ğŸ• ì‹œì‘ ì‹œê°„: ${new Date().toLocaleTimeString()}.${this.recordingStartTime % 1000}`)
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
    } catch (e) {
      console.error('âŒ ë…¹ìŒ ì‹¤íŒ¨:', e)
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
    }
  }

  private stopRecording(): void {
    const now = Date.now()
    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
    console.log(`ğŸ›‘ [stopRecording í˜¸ì¶œ] ${new Date().toLocaleTimeString()}.${now % 1000}`)
    console.log(`   ğŸ“Š ìƒíƒœ:`)
    console.log(`      - isRecording: ${this.isRecording}`)
    console.log(`      - mediaRecorder: ${this.mediaRecorder ? 'âœ… ìˆìŒ' : 'âŒ ì—†ìŒ'}`)
    console.log(`      - isWaitingForAIResponse: ${this.isWaitingForAIResponse ? 'â›” true' : 'âœ… false'}`)
    console.log(`      - isAIResponding: ${this.isAIResponding ? 'â›” true' : 'âœ… false'}`)

    if (!this.isRecording || !this.mediaRecorder) {
      const reason = !this.isRecording ? 'ë…¹ìŒ ì¤‘ì´ ì•„ë‹˜' : 'mediaRecorder ì—†ìŒ'
      console.log(`   âš ï¸  ì¤‘ì§€ ë¶ˆê°€: ${reason}`)
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
      return
    }

    console.log(`   âœ… ì¤‘ì§€ ì¡°ê±´ ë§Œì¡±`)

    try {
      this.mediaRecorder.stop()
      this.isRecording = false
      const stopTime = Date.now()
      console.log(`   âœ… MediaRecorder.stop() í˜¸ì¶œ ì™„ë£Œ`)
      console.log(`   ğŸ”“ isRecording = false ì„¤ì •`)
      console.log(`   ğŸ• ì¤‘ì§€ ì‹œê°„: ${new Date().toLocaleTimeString()}.${stopTime % 1000}`)
      console.log(`   â±ï¸  stop() ì†Œìš” ì‹œê°„: ${stopTime - now}ms`)
      console.log(`   â³ onstop ì½œë°± ëŒ€ê¸° ì¤‘...`)
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
    } catch (e) {
      console.error('âŒ ì¤‘ì§€ ì‹¤íŒ¨:', e)
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
    }
  }

  private sendAudio(blob: Blob): void {
    const now = Date.now()
    const timeSinceLastSent = this.lastAudioSentTime > 0 ? now - this.lastAudioSentTime : 0

    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
    console.log(`ğŸ“¤ [sendAudio í˜¸ì¶œ] ì˜¤ë””ì˜¤ ì „ì†¡ ì‹œë„`)
    console.log(`   ğŸ• í˜¸ì¶œ ì‹œê°„: ${new Date().toLocaleTimeString()}.${now % 1000}`)
    console.log(`   â±ï¸  ë§ˆì§€ë§‰ ì „ì†¡ í›„ ê²½ê³¼: ${timeSinceLastSent > 0 ? (timeSinceLastSent / 1000).toFixed(3) + 'ì´ˆ' : 'N/A'}`)
    console.log(`   ğŸ“¦ í¬ê¸°: ${(blob.size / 1024).toFixed(1)}KB`)
    console.log(`   ğŸ“Š ìƒíƒœ:`)
    console.log(`      - isRecording: ${this.isRecording}`)
    console.log(`      - isWaitingForAIResponse: ${this.isWaitingForAIResponse ? 'â›” true' : 'âœ… false'}`)
    console.log(`      - isAIResponding: ${this.isAIResponding ? 'â›” true' : 'âœ… false'}`)
    console.log(`      - audioSentCount: ${this.audioSentCount}`)
    console.log(`      - aiResponseCount: ${this.aiResponseCount}`)

    // ì²« ë²ˆì§¸ ì²´í¬: sendAudio ì§„ì… ì‹œì 
    if (this.isAIResponding || this.isWaitingForAIResponse) {
      const reason = this.isWaitingForAIResponse ? 'AI ì‘ë‹µ ëŒ€ê¸° ì¤‘' : 'AI ì‘ë‹µ ì¤‘'
      console.log(`âŒ [ì°¨ë‹¨ #1 - ì§„ì…ì‹œ] ${reason} - ì „ì†¡ ì¦‰ì‹œ ì·¨ì†Œ`)
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
      return
    }

    if (blob.size < 15000) {
      console.log(`âš ï¸ [ì°¨ë‹¨ - í¬ê¸°] ë„ˆë¬´ ì‘ìŒ: ${(blob.size / 1024).toFixed(1)}KB < 15KB`)
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
      return
    }

    console.log(`   Socket: ${this.socket ? 'âœ… ì—°ê²°ë¨' : 'âŒ ì—†ìŒ'}`)
    console.log(`   Session ID: ${this.sessionId ? 'âœ… ' + this.sessionId : 'âŒ ì—†ìŒ'}`)
    console.log(`   Call ID: ${this.callId ? 'âœ… ' + this.callId : 'âŒ ì—†ìŒ'}`)

    const reader = new FileReader()
    reader.onloadend = () => {
      const readerTime = Date.now()
      console.log(`   ğŸ”„ [FileReader ì™„ë£Œ] ì‹œê°„: ${new Date().toLocaleTimeString()}.${readerTime % 1000}`)
      console.log(`   â±ï¸  FileReader ì²˜ë¦¬ ì‹œê°„: ${readerTime - now}ms`)

      // ë‘ ë²ˆì§¸ ì²´í¬: FileReader ì™„ë£Œ í›„
      if (this.isAIResponding || this.isWaitingForAIResponse) {
        const reason = this.isWaitingForAIResponse ? 'AI ì‘ë‹µ ëŒ€ê¸° ì¤‘' : 'AI ì‘ë‹µ ì¤‘'
        console.log(`âŒ [ì°¨ë‹¨ #2 - FileReader í›„] ${reason} - ì „ì†¡ ì·¨ì†Œ`)
        console.log(`   ìƒíƒœ: isWaiting=${this.isWaitingForAIResponse}, isResponding=${this.isAIResponding}`)
        console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
        return
      }

      if (this.socket && this.sessionId && this.callId) {
        const base64Data = (reader.result as string).split(',')[1]
        console.log(`   ğŸ“ Base64 ê¸¸ì´: ${base64Data.length} chars`)

        // ì„¸ ë²ˆì§¸ ì²´í¬: emit ì§ì „
        if (this.isAIResponding || this.isWaitingForAIResponse) {
          const reason = this.isWaitingForAIResponse ? 'AI ì‘ë‹µ ëŒ€ê¸° ì¤‘' : 'AI ì‘ë‹µ ì¤‘'
          console.log(`âŒ [ì°¨ë‹¨ #3 - emit ì§ì „] ${reason} - ì „ì†¡ ì·¨ì†Œ`)
          console.log(`   ìƒíƒœ: isWaiting=${this.isWaitingForAIResponse}, isResponding=${this.isAIResponding}`)
          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          return
        }

        // ğŸ”’ ìƒíƒœ ë³€ê²½ (ì „ì†¡ ì§ì „)
        const beforeEmit = Date.now()
        this.isWaitingForAIResponse = true
        this.lastAudioSentTime = beforeEmit
        console.log(`ğŸ”’ [ìƒíƒœ ë³€ê²½] isWaitingForAIResponse = true`)
        console.log(`   ğŸ• ì„¤ì • ì‹œê°„: ${new Date().toLocaleTimeString()}.${beforeEmit % 1000}`)

        this.socket.emit('user-audio', {
          sessionId: this.sessionId,
          callId: this.callId,
          audioData: base64Data,
          mimeType: 'audio/webm',
        })

        this.audioSentCount++
        const afterEmit = Date.now()
        console.log(`âœ… [ì „ì†¡ ì™„ë£Œ] ì„œë²„ë¡œ ì „ì†¡ ì„±ê³µ! (#${this.audioSentCount})`)
        console.log(`   ğŸ• emit ì™„ë£Œ ì‹œê°„: ${new Date().toLocaleTimeString()}.${afterEmit % 1000}`)
        console.log(`   â±ï¸  emit ì†Œìš” ì‹œê°„: ${afterEmit - beforeEmit}ms`)
        console.log(`â³ AI ì‘ë‹µ ëŒ€ê¸° ì¤‘... (isWaitingForAIResponse = true)`)
        console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
        this.emitVADStatus()
      } else {
        console.error(`âŒ ì „ì†¡ ì‹¤íŒ¨! - ì—°ê²° ì •ë³´ ì—†ìŒ`)
        console.error(`   Socket: ${this.socket ? 'ìˆìŒ' : 'âŒ ì—†ìŒ'}`)
        console.error(`   Session ID: ${this.sessionId || 'âŒ ì—†ìŒ'}`)
        console.error(`   Call ID: ${this.callId || 'âŒ ì—†ìŒ'}`)
        console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
      }
    }
    reader.readAsDataURL(blob)
  }

  async connectToServer(onRemoteStream: (stream: MediaStream) => void): Promise<void> {
    if (!this.sessionId) {
      throw new Error('Session IDê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € startCall()ì„ í˜¸ì¶œí•˜ì„¸ìš”.')
    }

    // WebRTC ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    const rtcConfig = await this.getWebRTCConfig()

    // Socket.IO ì—°ê²°
    this.socket = io(WEBSOCKET_URL, {
      transports: ['websocket', 'polling'],
    })

    // ë¡œì»¬ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸°
    this.localStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
        sampleRate: 48000,
      },
      video: false,
    })

    // AudioContext ì´ˆê¸°í™”
    this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
    this.analyser = this.audioContext.createAnalyser()
    this.analyser.fftSize = 2048
    this.analyser.smoothingTimeConstant = 0.8
    const source = this.audioContext.createMediaStreamSource(this.localStream)
    source.connect(this.analyser)
    console.log('âœ… AudioContext ì´ˆê¸°í™”')

    // RTCPeerConnection ìƒì„±
    this.peerConnection = new RTCPeerConnection(rtcConfig)

    // ë¡œì»¬ ìŠ¤íŠ¸ë¦¼ ì¶”ê°€
    this.localStream.getTracks().forEach((track) => {
      if (this.peerConnection && this.localStream) {
        this.peerConnection.addTrack(track, this.localStream)
      }
    })

    // ì›ê²© ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹ 
    this.peerConnection.ontrack = (event) => {
      if (event.streams && event.streams[0]) {
        onRemoteStream(event.streams[0])
      }
    }

    // ICE Candidate ì²˜ë¦¬
    this.peerConnection.onicecandidate = (event) => {
      if (event.candidate && this.socket && this.sessionId) {
        this.socket.emit('ice-candidate', {
          sessionId: this.sessionId,
          peerId: this.peerId,
          candidate: event.candidate,
        })
      }
    }

    // WebSocket ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
    this.setupSocketListeners()

    // ì„¸ì…˜ ì°¸ì—¬
    this.socket.emit('join-session', {
      sessionId: this.sessionId,
      peerId: this.peerId,
    })

    // Offer ìƒì„± ë° ì „ì†¡
    const offer = await this.peerConnection.createOffer()
    await this.peerConnection.setLocalDescription(offer)

    this.socket.emit('offer', {
      sessionId: this.sessionId,
      peerId: this.peerId,
      offer,
    })

    // í†µí™” ì—°ê²°
    if (this.callId) {
      await fetch(`${API_BASE_URL}/calls/${this.callId}/connect`, {
        method: 'POST',
      })
    }

    // ì²« AI ì¸ì‚¬ë§ ëŒ€ê¸° ìƒíƒœë¡œ ì‹œì‘
    this.isWaitingForAIResponse = true
    console.log('â³ ì²« AI ì¸ì‚¬ë§ ëŒ€ê¸° ì¤‘...')

    // VAD ì‹œì‘
    this.startVADChecking()
    console.log('âœ… VAD í™œì„±í™”')
  }

  private setupSocketListeners(): void {
    if (!this.socket) return

    this.socket.on('joined-session', ({ sessionId, peerId }) => {
      console.log('ì„¸ì…˜ ì°¸ì—¬ ì™„ë£Œ:', sessionId, peerId)
    })

    this.socket.on('peer-joined', ({ peerId }) => {
      console.log('í”¼ì–´ ì°¸ì—¬:', peerId)
    })

    this.socket.on('answer', async ({ answer }) => {
      if (this.peerConnection) {
        await this.peerConnection.setRemoteDescription(new RTCSessionDescription(answer))
      }
    })

    this.socket.on('ice-candidate', async ({ candidate }) => {
      if (this.peerConnection && candidate) {
        await this.peerConnection.addIceCandidate(new RTCIceCandidate(candidate))
      }
    })

    this.socket.on('peer-left', ({ peerId }) => {
      console.log('í”¼ì–´ ë‚˜ê°:', peerId)
    })

    this.socket.on('peer-disconnected', ({ peerId }) => {
      console.log('í”¼ì–´ ì—°ê²° ëŠê¹€:', peerId)
    })

    // AI ì‘ë‹µ ìˆ˜ì‹ 
    this.socket.on('ai-audio-response', ({ audioData }) => {
      const responseTime = Date.now()
      const timeSinceLastSent = this.lastAudioSentTime > 0 ? responseTime - this.lastAudioSentTime : 0

      console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
      console.log('ğŸ¤– [AI ì‘ë‹µ ìˆ˜ì‹ ] AI ì˜¤ë””ì˜¤ ì‘ë‹µ ë„ì°©!')
      console.log(`   ğŸ• ìˆ˜ì‹  ì‹œê°„: ${new Date().toLocaleTimeString()}.${responseTime % 1000}`)
      console.log(`   â±ï¸  ë§ˆì§€ë§‰ ì „ì†¡ í›„ ê²½ê³¼: ${timeSinceLastSent > 0 ? (timeSinceLastSent / 1000).toFixed(3) + 'ì´ˆ' : 'N/A'}`)
      console.log(`   ğŸ“Š ìƒíƒœ (ë³€ê²½ ì „):`)
      console.log(`      - isWaitingForAIResponse: ${this.isWaitingForAIResponse}`)
      console.log(`      - isAIResponding: ${this.isAIResponding}`)
      console.log(`      - audioSentCount: ${this.audioSentCount}`)
      console.log(`      - aiResponseCount: ${this.aiResponseCount}`)

      // ì²« AI ì‘ë‹µì´ë©´ ì½œë°± í˜¸ì¶œ (ì—°ê²°ìŒ ì¤‘ì§€ìš©)
      if (this.aiResponseCount === 0 && this.onFirstAIResponse) {
        console.log(`   ğŸ‰ ì²« AI ì‘ë‹µ! - ì—°ê²°ìŒ ì¤‘ì§€ ì½œë°± í˜¸ì¶œ`)
        this.onFirstAIResponse()
      }

      // ëŒ€ê¸° ìƒíƒœ í•´ì œ ë° ì‘ë‹µ ì¤‘ ìƒíƒœë¡œ ì „í™˜
      this.isWaitingForAIResponse = false
      this.isAIResponding = true
      console.log(`ğŸ”“ [ìƒíƒœ ë³€ê²½] isWaitingForAIResponse = false`)
      console.log(`ğŸ”’ [ìƒíƒœ ë³€ê²½] isAIResponding = true`)
      console.log(`   âœ… AI ì‘ë‹µ ëŒ€ê¸° ì¢…ë£Œ â†’ AI ì‘ë‹µ ì¬ìƒ ì‹œì‘`)
      this.emitVADStatus()

      try {
        // Base64 ë””ì½”ë”©
        const binaryString = atob(audioData)
        const bytes = new Uint8Array(binaryString.length)
        for (let i = 0; i < binaryString.length; i++) {
          bytes[i] = binaryString.charCodeAt(i)
        }
        const blob = new Blob([bytes], { type: 'audio/mp3' })

        // ì½œë°± í˜¸ì¶œ
        if (this.onAIResponse) {
          this.onAIResponse(blob)
        }

        // ìë™ ì¬ìƒ
        const audio = new Audio(URL.createObjectURL(blob))
        const playStartTime = Date.now()

        audio.onended = () => {
          const endTime = Date.now()
          const playDuration = endTime - playStartTime

          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          console.log(`âœ… [AI ì‘ë‹µ ì¬ìƒ ì™„ë£Œ] ${new Date().toLocaleTimeString()}.${endTime % 1000}`)
          console.log(`   â±ï¸  ì¬ìƒ ì‹œê°„: ${(playDuration / 1000).toFixed(2)}ì´ˆ`)
          console.log(`   ğŸ“Š ìƒíƒœ ë³€ê²½ ì „:`)
          console.log(`      - isAIResponding: ${this.isAIResponding} â†’ false`)
          console.log(`      - isWaitingForAIResponse: ${this.isWaitingForAIResponse}`)
          console.log(`      - isRecording: ${this.isRecording}`)
          console.log(`      - isSpeaking: ${this.isSpeaking}`)

          this.isAIResponding = false
          this.aiResponseCount++

          console.log(`   ğŸ”“ [ìƒíƒœ ë³€ê²½] isAIResponding = false`)
          console.log(`   ğŸ“ˆ aiResponseCount = ${this.aiResponseCount}`)
          console.log(`   ğŸ¤ ì‚¬ìš©ì ìŒì„± ì…ë ¥ ëŒ€ê¸° ì‹œì‘!`)
          console.log(`   âœ… ì´ì œ ë…¹ìŒ ê°€ëŠ¥ ìƒíƒœ`)
          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          this.emitVADStatus()
        }

        audio.onerror = (e) => {
          const errorTime = Date.now()
          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          console.log(`âŒ [AI ì¬ìƒ ì‹¤íŒ¨] ${new Date().toLocaleTimeString()}.${errorTime % 1000}`)
          console.error('   ì—ëŸ¬:', e)
          console.log(`   ğŸ“Š ìƒíƒœ ë³µêµ¬:`)
          console.log(`      - isAIResponding: ${this.isAIResponding} â†’ false`)
          console.log(`      - isWaitingForAIResponse: ${this.isWaitingForAIResponse} â†’ false`)

          this.isAIResponding = false
          this.isWaitingForAIResponse = false

          console.log(`   âœ… ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ`)
          console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
          this.emitVADStatus()
        }

        audio.play()
        console.log(`   ğŸ”Š [ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘] ${new Date().toLocaleTimeString()}.${playStartTime % 1000}`)
        console.log(`   â³ ì¬ìƒ ì™„ë£Œ ëŒ€ê¸° ì¤‘...`)
      } catch (e) {
        this.isAIResponding = false
        console.error('âŒ AI ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨:', e)
        this.emitVADStatus()
      }
    })
  }

  async endCall(): Promise<void> {
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    console.log('ğŸ›‘ í†µí™” ì¢…ë£Œ ì‹œì‘')

    // VAD ì¤‘ì§€
    if (this.vadCheckInterval) {
      clearInterval(this.vadCheckInterval)
      this.vadCheckInterval = null
      console.log('âœ… VAD ì¤‘ì§€')
    }

    // ë…¹ìŒ ì¤‘ì§€
    if (this.isRecording && this.mediaRecorder) {
      this.mediaRecorder.stop()
      this.isRecording = false
      console.log('âœ… ë…¹ìŒ ì¤‘ì§€')
    }

    // AudioContext ì¢…ë£Œ
    if (this.audioContext) {
      await this.audioContext.close()
      this.audioContext = null
      this.analyser = null
      console.log('âœ… AudioContext ì¢…ë£Œ')
    }

    // í†µí™” ì¢…ë£Œ API í˜¸ì¶œ
    if (this.callId) {
      await fetch(`${API_BASE_URL}/calls/${this.callId}/end`, {
        method: 'POST',
      })
      console.log('âœ… í†µí™” ì¢…ë£Œ API í˜¸ì¶œ')
    }

    // PeerConnection ì¢…ë£Œ
    if (this.peerConnection) {
      this.peerConnection.close()
      this.peerConnection = null
      console.log('âœ… PeerConnection ì¢…ë£Œ')
    }

    // ë¡œì»¬ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
    if (this.localStream) {
      this.localStream.getTracks().forEach((track) => track.stop())
      this.localStream = null
      console.log('âœ… ë¡œì»¬ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ')
    }

    // Socket ì—°ê²° ì¢…ë£Œ
    if (this.socket && this.sessionId) {
      this.socket.emit('leave-session', {
        sessionId: this.sessionId,
        peerId: this.peerId,
      })
      this.socket.disconnect()
      this.socket = null
      console.log('âœ… WebSocket ì¢…ë£Œ')
    }

    // ì´ˆê¸°í™”
    this.callId = null
    this.sessionId = null
    this.audioSentCount = 0
    this.aiResponseCount = 0
    this.isSpeaking = false
    this.isAIResponding = false
    this.isWaitingForAIResponse = false
    this.isRecording = false

    console.log('âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ')
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
  }

  getCallId(): string | null {
    return this.callId
  }

  getSessionId(): string | null {
    return this.sessionId
  }

  isConnected(): boolean {
    return this.peerConnection !== null && this.socket !== null
  }
}

export const webrtcService = new WebRTCService()
